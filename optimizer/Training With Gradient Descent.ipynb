{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LINEAR REGRESSION\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], tf.float32, name=\"W\")\n",
    "b = tf.Variable([-.3], tf.float32, name=\"b\")\n",
    "# model input\n",
    "x = tf.placeholder(tf.float32, name=\"x\") # data point\n",
    "linear_model = W * x + b\n",
    "init = tf.global_variables_initializer()\n",
    "# initializes the W and b to its default value \n",
    "#    [.3] and [-.3] respectively\n",
    "sess.run(init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LOSS FUNCTION\n",
    "# model output\n",
    "y = tf.placeholder(tf.float32, name=\"y\")\n",
    "# sq_delt = (y_hat - y)^2\n",
    "squared_deltas = tf.square(linear_model - y, name=\"sq_delt\")\n",
    "loss = tf.reduce_sum(squared_deltas, name=\"sum_sq_delt\") # sum of squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIMIZERS\n",
    "# tf has some cool optimzers that helps us minimize\n",
    "#  the loss function! wow!\n",
    "# here, it is done by gradient descent.\n",
    "# given a model, tf can generate the derivative of the \n",
    "#  loss function! wow! so cool!\n",
    "# here, the learning rate is set to 0.01\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01, name=\"gradient\")\n",
    "train = optimizer.minimize(loss, name=\"optimizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "for i in range(1000):\n",
    "    # lol... training on the same data point \n",
    "    #  all day, every day\n",
    "    sess.run(train, {x:x_train, y:y_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writes the current state into a serializable format\n",
    "# to visualize the graph from sess.graph, \n",
    "#  tensorboard --logdir=.\n",
    "#  go to localhost:6006\n",
    "file_writer = tf.summary.FileWriter('.', sess.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
